{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Utiliser des données\n",
        "\n",
        "Les données sont le fondement sur lequel les modèles d’apprentissage automatique sont construits. Le gestion des données de manière centralisée dans le cloud et leur accessibilité aux équipes de scientifiques des données qui exécutent des essais et des modèles d’apprentissage sur plusieurs stations de travail et cibles de calcul constituent une partie importante de toute solution professionnelle de science des données.\n",
        "\n",
        "Dans ce notebook, vous allez explorer deux objets Azure Machine Learning pour l’utilisation des données\u00A0: *magasins de données* et *ressources de données*.\n",
        "\n",
        "## Avant de commencer\n",
        "\n",
        "Vous devez avoir la dernière version du package **azureml-ai-ml** pour exécuter le code dans ce notebook. Exécutez la cellule ci-dessous pour vérifier qu’il est installé.\n",
        "\n",
        "> **Remarque**\u00A0:\n",
        "> Si le package **azure-ai-ml** n’est pas installé, exécutez `pip install azure-ai-ml` pour l’installer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789326586
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Se connecter à un espace de travail\n",
        "\n",
        "Une fois les packages requis du Kit de développement logiciel (SDK) installés, vous êtes prêt à vous connecter à votre espace de travail.\n",
        "\n",
        "Pour vous connecter à un espace de travail, vous avez besoin de paramètres d’identificateur\u00A0: un ID d’abonnement, un nom de groupe de ressources et un nom d’espace de travail. Le nom du groupe de ressources et le nom de l’espace de travail sont déjà renseignés pour vous. Vous avez seulement besoin de l’ID d’abonnement pour exécuter la commande.\n",
        "\n",
        "Pour trouver les paramètres nécessaires, cliquez sur l’abonnement et le nom de l’espace de travail en haut à droite du studio. Un volet s’ouvre à droite.\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> Copiez l’ID d’abonnement et remplacez **YOUR-SUBSCRIPTION-ID** par la valeur que vous avez copiée. </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Lister les magasins de données\n",
        "\n",
        "Quand vous créez l’espace de travail Azure Machine Learning, un compte de stockage Azure est également créé. Le compte de stockage inclut le stockage d’objets blob et le stockage de fichiers, qui sont automatiquement connectés avec votre espace de travail en tant que **magasins de données**. Vous pouvez lister tous les magasins de données connectés à votre espace de travail\u00A0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789343369
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Notez le `workspaceblobstore` qui se connecte au conteneur **azureml-blobstore-...** que vous avez exploré précédemment. Le `workspacefilestore` se connecte au partage de fichiers **code-...** ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Créer une banque de données\n",
        "\n",
        "Chaque fois que vous souhaitez connecter un autre service de stockage Azure à l’espace de travail Azure Machine Learning, vous pouvez créer un magasin de données. Notez que la création d’un magasin de données crée la connexion entre votre espace de travail et le stockage. Elle ne crée pas le service de stockage lui-même. \n",
        "\n",
        "Pour créer un magasin de données et vous connecter à un stockage (déjà existant), vous devez spécifier\u00A0:\n",
        "\n",
        "- La classe permettant d’indiquer le type de service de stockage avec lequel vous souhaitez vous connecter. L’exemple ci-dessous illustre une connexion à un stockage d’objets blob (`AzureBlobDatastore`).\n",
        "- `name`\u00A0: nom complet du magasin de données dans l’espace de travail Azure Machine Learning.\n",
        "- `description`\u00A0: description facultative pour fournir plus d’informations sur le magasin de données.\n",
        "- `account_name`\u00A0: nom du compte Stockage Azure.\n",
        "- `container_name`\u00A0: nom du conteneur pour stocker les objets blob dans le compte de stockage Azure.\n",
        "- `credentials`\u00A0: fournissez la méthode d’authentification et les informations d’identification nécessaires à l’authentification. L’exemple ci-dessous utilise une clé de compte.\n",
        "\n",
        "**Important\u00A0!** \n",
        "- Remplacez **YOUR-STORAGE-ACCOUNT-NAME** par le nom du compte de stockage créé automatiquement pour vous. \n",
        "- Remplacez **XXXX-XXXX** pour `account_key` par la clé de compte de votre compte Stockage Azure. \n",
        "\n",
        "N’oubliez pas que vous pouvez récupérer la clé de compte dans le [portail Azure](https://portal.azure.com)\u00A0: accédez à votre compte de stockage, puis, sous l’onglet **Clés d’accès**, copiez la valeur **Clé** pour key1 ou key2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Relistez les magasins de données pour vérifier qu’un magasin de données nommé `blob_training_data` a été créé\u00A0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790805418
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Créer des ressources de données\n",
        "\n",
        "Pour pointer vers un dossier ou un fichier spécifique dans un magasin de données, vous pouvez créer des ressources de données. Il existe trois types de ressources de données\u00A0:\n",
        "\n",
        "- `URI_FILE` pointe vers un fichier spécifique.\n",
        "- `URI_FOLDER` pointe vers un dossier spécifique.\n",
        "- `MLTABLE` pointe vers un fichier MLTable qui spécifie comment lire un ou plusieurs fichiers dans un dossier.\n",
        "\n",
        "Vous allez créer les trois types de ressources de données pour découvrir les différences entre elles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour créer une ressource de données `URI_FILE`, vous devez spécifier un chemin qui pointe vers un fichier spécifique. Le chemin peut être un chemin local ou un chemin cloud.\n",
        "\n",
        "Dans l’exemple ci-dessous, vous allez créer une ressource de données en référençant un chemin *local*. Pour que les données soient toujours disponibles lors de l’utilisation de l’espace de travail Azure Machine Learning, les fichiers locaux sont automatiquement chargés sur le magasin de données par défaut. En l’occurrence, le fichier `diabetes.csv` est chargé sur le dossier **LocalUpload** dans le magasin de données **workspaceblobstore**. \n",
        "\n",
        "Pour créer une ressource de données à partir d’un fichier local, exécutez la cellule suivante\u00A0:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Pour créer une ressource de données `URI_FOLDER`, vous devez spécifier un chemin qui pointe vers un dossier spécifique. Le chemin peut être un chemin local ou un chemin cloud.\n",
        "\n",
        "Dans l’exemple ci-dessous, vous allez créer une ressource de données en référençant un chemin *cloud*. Le chemin n’a pas encore besoin d’exister. Le dossier est créé quand les données sont chargées sur le chemin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790818340
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Pour créer une ressource de données `MLTable`, vous devez spécifier un chemin qui pointe vers un dossier qui contient un fichier MLTable. Le chemin peut être un chemin local ou un chemin cloud. \n",
        "\n",
        "Dans l’exemple ci-dessous, vous allez créer une ressource de données en référençant un chemin *local* qui contient un fichier MLTable et CSV. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Pour vérifier que les ressources de données ont été créées, vous pouvez relister toutes les ressources de données dans l’espace de travail :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790835295
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Lire des données dans un notebook\n",
        "\n",
        "Au départ, vous souhaiterez peut-être utiliser des ressources de données dans des notebooks pour explorer les données et expérimenter des modèles Machine Learning. Les ressources de données de type `URI_FILE` ou `URI_FOLDER` sont lues de la même façon que des données ordinaires. Par exemple, pour lire un fichier CSV vers lequel pointe une ressource de données, vous pouvez utiliser la fonction pandas `read_csv()`. \n",
        "\n",
        "Une ressource de données de type `MLTable` est déjà *lue* par le fichier **MLTable**, qui spécifie le schéma et comment interpréter les données. Étant donné que les données sont déjà *lues*, vous pouvez facilement convertir une ressource de données MLTable en dataframe pandas. \n",
        "\n",
        "Vous devez installer la bibliothèque `mltable` (ce que vous avez fait dans le terminal). Ensuite, vous pouvez convertir la ressource de données en dataframe et visualiser les données.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Utiliser des données dans un travail\n",
        "\n",
        "Après avoir utilisé un notebook pour l’expérimentation. Vous pouvez utiliser des scripts pour entraîner des modèles Machine Learning. Un script peut être exécuté en tant que travail, et pour chaque travail, vous pouvez spécifier des entrées et des sorties. \n",
        "\n",
        "Vous pouvez utiliser des **ressources de données** ou des **chemins de magasin de données** comme entrées ou sorties d’un travail. \n",
        "\n",
        "Les cellules ci-dessous créent le script **move-data.py** dans le dossier **src**. Le script lit les données d’entrée avec la fonction `read_csv()`. Le script stocke ensuite les données sous forme de fichier CSV dans le chemin de sortie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Pour envoyer un travail qui exécute le script **move-data.py**, exécutez la cellule ci-dessous. \n",
        "\n",
        "Le travail est configuré pour utiliser la ressource de données `diabetes-local`, en pointant vers le fichier **diabetes.csv** local en guise d’entrée. La sortie est un chemin pointant vers un dossier dans le nouveau magasin de données `blob_training_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790852019
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_path = './data/diabetes.csv'\n",
        "\n",
        "my_data = Data(\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
        "    name=\"diabetes-local\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `URI_FOLDER` data asset, you have to specify a path that points to a specific folder. The path can be a local path or cloud path.\n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *cloud* path. The path doesn't have to exist yet. The folder will be created when data is uploaded to the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666793449117
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "datastore_path = 'azureml://datastores/blob_training_data/paths/data-asset-path/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=datastore_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"Data asset pointing to data-asset-path folder in datastore\",\n",
        "    name=\"diabetes-datastore-path\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `MLTable` data asset, you have to specify a path that points to a folder which contains a MLTable file. The path can be a local path or cloud path. \n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *local* path which contains an MLTable and CSV file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790884342
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "local_path = 'data/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=local_path,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"MLTable pointing to diabetes.csv in data folder\",\n",
        "    name=\"diabetes-table\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To verify that the new data assets have been created, you can list all data assets in the workspace again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790894246
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "datasets = ml_client.data.list()\n",
        "for ds_name in datasets:\n",
        "    print(ds_name.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Read data in notebook\n",
        "\n",
        "Initially, you may want to work with data assets in notebooks, to explore the data and experiment with machine learning models. Any `URI_FILE` or `URI_FOLDER` type data assets are read as you would normally read data. For example, to read a CSV file a data asset points to, you can use the pandas function `read_csv()`. \n",
        "\n",
        "A `MLTable` type data asset is already *read* by the **MLTable** file, which specifies the schema and how to interpret the data. Since the data is already *read*, you can easily convert a MLTable data asset to a pandas dataframe. \n",
        "\n",
        "You'll need to install the `mltable` library (which you did in the terminal). Then, you can convert the data asset to a dataframe and visualize the data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666792246101
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import mltable\n",
        "\n",
        "registered_data_asset = ml_client.data.get(name='diabetes-table', version=1)\n",
        "tbl = mltable.load(f\"azureml:/{registered_data_asset.id}\")\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Use data in a job\n",
        "\n",
        "After using a notebook for experimentation. You can use scripts to train machine learning models. A script can be run as a job, and for each job you can specify inputs and outputs. \n",
        "\n",
        "You can use either **data assets** or **datastore paths** as inputs or outputs of a job. \n",
        "\n",
        "The cells below creates the **move-data.py** script in the **src** folder. The script reads the input data with the `read_csv()` function. The script then stores the data as a CSV file in the output path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile $script_folder/move-data.py\n",
        "# import libraries\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.input_data)\n",
        "\n",
        "    output_df = df.to_csv((Path(args.output_datastore) / \"diabetes.csv\"), index = False)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Count the rows and print the result\n",
        "    row_count = (len(df))\n",
        "    print('Analyzing {} rows of data'.format(row_count))\n",
        "    \n",
        "    return df\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--input_data\", dest='input_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--output_datastore\", dest='output_datastore',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To submit a job that runs the **move-data.py** script, run the cell below. \n",
        "\n",
        "The job is configured to use the data asset `diabetes-local`, pointing to the local **diabetes.csv** file as input. The output is a path pointing to a folder in the new datastore `blob_training_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666794414231
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import command\n",
        "\n",
        "# configure input and output\n",
        "my_job_inputs = {\n",
        "    \"local_data\": Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-local:1\")\n",
        "}\n",
        "\n",
        "my_job_outputs = {\n",
        "    \"datastore_data\": Output(type=AssetTypes.URI_FOLDER, path=\"azureml://datastores/blob_training_data/paths/datastore-path\")\n",
        "}\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python move-data.py --input_data ${{inputs.local_data}} --output_datastore ${{outputs.datastore_data}}\",\n",
        "    inputs=my_job_inputs,\n",
        "    outputs=my_job_outputs,\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"move-diabetes-data\",\n",
        "    experiment_name=\"move-diabetes-data\"\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}